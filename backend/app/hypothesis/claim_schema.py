"""Claim schema definitions."""

from typing import Any, Literal
from pydantic import BaseModel, Field


class ClaimSubject(BaseModel):
    """Subject of a claim."""

    candidate_id: str
    application_id: str
    simulation_run_id: str | None = None


class Claim(BaseModel):
    """A claim about a candidate that requires proof.

    Claims are generated by the hypothesis generator and then
    verified by the proof engine using evidence and rules.
    """

    claim_type: str = Field(..., description="Type identifier for the claim")
    subject: ClaimSubject = Field(..., description="What/who the claim is about")
    statement: str = Field(..., description="Human-readable claim statement")
    dimensions: list[str] = Field(
        default_factory=list,
        description="Evaluation dimensions this claim relates to (e.g., debugging, testing)",
    )
    confidence: float = Field(
        default=0.0,
        ge=0.0,
        le=1.0,
        description="Internal confidence score (0-1)",
    )
    evidence_requirements: list[str] = Field(
        default_factory=list,
        description="Types of evidence needed to prove this claim",
    )


class EvidenceRef(BaseModel):
    """Reference to evidence supporting a claim."""

    type: Literal["artifact", "metric", "llm_tag"] = Field(..., description="Type of evidence")
    id: str = Field(..., description="ID of the evidence (artifact_id, metric_id, etc.)")
    field: str | None = Field(None, description="Specific field or value from the evidence")
    value: Any = Field(None, description="The actual value from the evidence")


class ProofResult(BaseModel):
    """Result of attempting to prove a claim."""

    claim: Claim
    status: Literal["PROVED", "UNPROVED"] = Field(..., description="Proof status")
    evidence_refs: list[EvidenceRef] = Field(
        default_factory=list,
        description="Evidence used in proving/failing to prove",
    )
    rule_id: str = Field(..., description="ID of the rule used for evaluation")
    reason: str = Field("", description="Human-readable explanation of the result")


# Predefined claim types for v1
CLAIM_TYPES = {
    "added_regression_test": {
        "description": "Candidate added a regression test for the bug fix",
        "dimensions": ["testing_discipline"],
        "evidence_requirements": ["diff", "test_log", "metrics"],
    },
    "debugging_effective": {
        "description": "Candidate effectively diagnosed and fixed the bug",
        "dimensions": ["debugging_method"],
        "evidence_requirements": ["test_log", "metrics", "writeup"],
    },
    "testing_discipline": {
        "description": "Candidate demonstrates good testing practices",
        "dimensions": ["testing_discipline"],
        "evidence_requirements": ["diff", "test_log", "coverage"],
    },
    "communication_clear": {
        "description": "Candidate communicates clearly in writeup",
        "dimensions": ["communication"],
        "evidence_requirements": ["writeup", "llm_tags"],
    },
    "time_efficient": {
        "description": "Candidate completed task within expected time",
        "dimensions": ["shipping_speed"],
        "evidence_requirements": ["metrics"],
    },
    "handles_edge_cases": {
        "description": "Candidate properly handles edge cases",
        "dimensions": ["correctness"],
        "evidence_requirements": ["test_log", "diff"],
    },
}
